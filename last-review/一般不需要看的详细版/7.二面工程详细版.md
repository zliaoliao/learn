# 1. 部署

## 部署的发展历史

1). 一开始，直接将html部署到服务器，html直接引用的css；

但是我希望，html的引用的css是会走缓存的，用户不用每次都请求， 所以我们对html 引用的js, css使用强缓存；

不过这样，浏览器就不会去请求静态资源了，缓存如何更新呢？

有人想到： 更新页面中引用的资源路径（css换成一个新的路径去引用，比如在路径后加一个版本号等唯一标识），让浏览器主动放弃缓存，加载新资源；

2). 这时候，如果你的html有3个css资源, 这时你只改了第一个css文件，后两个没有没改，但是你打包时，是一起打包的，这样三个css都加上了版本号，这导致三个资源都会重新请求，但是其他两个我们是不希望刷缓存的，因为没变,那要怎么办呢？

这时，就需要数据摘要算法，对文件内容进行摘要，打包时，用摘要算法对比文件，如果文件更新，才会变更版本号。

3). 不过现在会用到cdn ,把静态资源和动态网页分开部署，静态资源（js,css, 图片）会被部署到cdn上，网页中引用的路径也会变成对应的部署路径。
> 所以我们会经常看到网页的域名，和网页内的静态资源域名不一直， 因为静态资源是cdn域名

这时又有一个文件，如果更新了，是先部署静态资源文件呢，还是先部署html?

如果先部署html: 那么在新的静态资源没部署好这段时间里，用户请求了就会拿到旧的资源，然后缓存起来，结果就是会访问到一个样式错乱的页面，除非手动刷下，新版本的静态资源被请求到，才会恢复正常
> 注意这是静态资源只是加了版本号，地址并没有变，只是避免了走缓存（相当于get加随机数避免缓存）

如果先部署静态资源： 那么在新的html没部署好这段时间里，用户访问了网页，用旧版静态资源缓存的用户，请求的页面是旧版本的，用的静态资源也是缓存的旧版本的，这时页面没有问题；但是没有静态资源缓存，或者缓存过期的用户，这时访问了页面，就会在旧的html里拿到新版本的静态资源，一样会样式错乱，执行出现问题，当新的html部署好，这部分用户再次访问就没问题；

所以，先部署谁都不行，都会出现问题；

这里的出现问题的根源在于路径没有变，只是在静态资源路径后加了版本号参数: ?v=xx

4）. 那么，我们打包时改掉文件名不就好了，把文件名后面加上前缀。

由ss.xxx.com/a.css?v=0abc1  改为  ss.xxx.com/a_oabc1.css

这时，我们先部署a_oabc1.css， 旧的html里引用的是a_oabc0.css， 就不会请求到新的静态资源，就不好出问题；

所以，现在用的大多是这套机制；  
1. 打包时给文件名加版本号，部署时，先部署静态资源，再部署html；
2. 静态资源缓存一年，html不缓存；


## 部署目的

一般初次部署的目的是将项目上线，并分配一个域名；

开发环境使用ts，react等进行代码编写， 通过webpack等进行打包；

在打包过程中可以进行优化：从减小体积，减少资源数量两个方面

减小体积： 更小的体积意味着更小更小的负载，更小的网络io, 更快的网页打开速度
  - 1. contentHash： 可以配置contentHash (将contentHash写进资源路径名), 当代码发生变更时，相应的css,js资源路径也会变更, 用户刷新html时就会去请求新的静态资源； 能够更精确的知道那些路径的hash值需要变；
    -   【配置在output, 下的 filename上】
  - 2. splitChunks: 可以将我们打包后的静态资源划分为多个chunk(即便只有一个页面也可以分为多个chunk); 假如我们只打包为一个bundle.js,这样我们组件的一行代码发生变更，我们所有bundle.js都会发生变更，就相当于我们整站的缓存都会失效；但是我们把它分成多个chunk之后，我们的组件发生变更后，只有对应的chunk才会变
  - 3. terser 之类的，对静态资源做一些压缩的配置




相关知识：

hash，chunkhash，contenthash：

- hash: 一次打包的hash值， 当任意module发生改变时，所有bundle（一次打包结果）的hash都改变且相同
- chunkhash： 根据不同的入口文(Entry)进行依赖文件解析，构建对应的chunk，生成对应的哈希值。
- contenthash： 每个静态资源文件的hash。 在打包时，我们会在js文件中导入CSS文件，因为他们是同一个入口文件，我们只改了JS代码，但是它的CSS在抽离生成CSS文件时hash也会跟着变，这个时候就需要contenthash来解决。


module, chunk, bundle

- module 模块，也就是一个文件 
- chunk 代码块，从某个入口出发找到的一系列依赖文件的统称， 这是 webpack 特定的术语被用在内部来管理 building 过程
  - 1. 一个entry入口对应一个chunk, 通常一个chunk 会对应一个 bundle，但是有一些配置并不会产生一对一的关系，比如MiniCssExtractPlugin，会把css代码从一个chunk里提取出来，独立生成一个bundle。
  - 2. Code Splitting: 它表示将你的代码拆分成多个bundle或chunk，之后你可以按需加载它们，而不是简单地加载一个单独的文件。
- bundle 是由webpack 打包出来的的具体文件
  - 1. bundle通常是由多个不同的模块产生，它是已经加载完毕和被编译后的源代码的最终版本。
  - 2. Bundle Splitting: 这是webpack优化代码的一种方法，即将一个单独的应用拆解为多个bundle。通过将多个bundle中公共引入的模块拆解出来，我们可以减少项目的代码量，从而减小应用的体积，并且通过浏览器缓存，我们可以将代码进一步优化。
  - 3. 最终效果是，当其他某些 bundle 的改动时，彼此独立的另一些 bundle 都可以不受到影响，减少需要重新发布的代码量，并利用浏览器缓存。

总体而言： 我们直接写出来的是 module，webpack 处理时是 chunk，最后生成浏览器可以直接运行的 bundle。

### 静态资源处理

对于打包后的静态资源，可以分为两类：一类是不带hash的静态资源（html）,一类是带hash的静态资源， 我们可以基于此对他们分配不同的缓存策略；

- 不带hash的静态资源： 设置Cache-Control: no-cache;  【每次询问服务器，资源是否有变化】（no-store 表示不缓存，每次请求新的）
- 带hash的静态资源： 设置Cache-Control： max-age=365*24*60*60; 也就是缓存一年的时间   



### 部署方式

使用docker 将我们的静态资源以nginx镜像，构建成新的镜像；
> 问题：镜像是个啥意思？

在此过程中我们可以使用docker对我们镜像做一些优化，来提高docker构建镜像的速度， 以及对我们生成镜像的体积进行优化；

在docker构建出新的镜像之后，我们可以将他推到我们的景象仓库中，公司中一般会搭建一个私有的镜像仓库， 我的的traefik或者k8s将会拉取镜像并将它进行部署，最后我们可以通过域名访问；

前端可以单独去配置我们的nginx.conf(nginx配置文件)，并将它添加到我们的前端镜像中，我们可以在nginx里做一些，cors, gzip,cache,rewrite和redirect(重定向)的操作， 这些配置一般要麻烦运维或者前端负责人去做；


除此之外，我们也可以将静态资源推到自己公司的oss（Object Storage Service, 对象存储服务）上，并通过cdn对oss进行加速，我们在看一些网站是，就会发现他们把静态资源放在一个单独的域名上
> oss就是将系统所要用的文件上传到云硬盘上，该云硬盘提供了文件下载、上传等一列服务，这样的服务以及技术可以统称为OSS

在此基础上我们可以做一些http的优化， 
  - 将http转为https, 而无需通过重定向；
  - tls1.3减少握手的次数
  - http2


开发代码提交之前，本地需要做一些git hook 的处理， 比如lint, commit message等一些代码规范性校验；

将本次更改提交会，要进行一系列ci的检查，比较镜像，依赖，打包大小，lint等，还有最重要的preview, 当我们将代码提交到功能分支并推送到远程仓库后,ci将自动对我们的功能分支新建一个测试环境，比如说功能分支为 f_a, 它会开启一个f_a.cra.tech, 对于这个域名它是自动取完成的，如此测试人员就可以在这个功能分支的测试环境对我们的代码进行测试；

接下来就是code review ,review之后可以将代码合并进主分支，然后进行自动部署

自动部署的过程中，我们就会开始上面的打包等一系列操作，最终上线，如果部署失败，或者在新环境中发生一些bug,我们就需要回滚，此时我们可以快速回滚到主分支的上一次部署环境




oss：一般是指阿里云oss， 不过一般大公司也会有自己的oss对象存储?

- 相关术语：

  - 存储空间（Bucket， 桶）： 存储空间是您用于存储对象（Object）的容器，所有的对象都必须隶属于某个存储空间。
  - 对象/文件（Object）： 对象是 OSS 存储数据的基本单元，也被称为OSS的文件。对象由元信息（Object Meta）、用户数据（Data）和文件名（Key）组成。对象由存储空间内部唯一的Key来标识。
  - 访问域名（Endpoint）： Endpoint 表示OSS对外服务的访问域名。
  - 访问密钥（AccessKey）：AccessKey，简称 AK，指的是访问身份验证中用到的AccessKeyId 和AccessKeySecret。AccessKeyId用于标识用户，AccessKeySecret是用户用于加密签名字符串和OSS用来验证签名字符串的密钥，其中AccessKeySecret 必须保密。

- oss的好处：
  - 平台无关的restful api接口
  - 稳定，安全，可靠
  - 低成本
  - 你可以使用阿里云提供的api/sdk 接口轻松的将海量数据移入或者移出阿里云

- 对象存储的缺点： 
  - 此类存储库将无法维护传统数据库。对象存储不允许按片段更改数据。只能修改整个对象，这会影响性能。例如，在文件系统中，您可以轻松地在日志末尾添加一行。在对象存储系统中，为此需要还原对象，添加新行并将整个对象写回。因此，这种存储不适用于数据经常变化的应用。
  - OSS非常适合存储静态资源， 如图像和电影，存储备份文件和日志。


### 为啥要使用静态资源服务器：nginx

我们是可以自己写后端服务器，然后将前端请求的静态资源文件返回的，比如最简单的返回html：
```

const html = fs.readFileSync('./index.html')
 
const server = http.createServer((req, res) => res.end(html))
server.listen(3000, () => {
  console.log('Listening 3000')
})

接下来启动代码，成功运行。

$ node server-fs.js
Listening 3000


```

但是对于纯静态资源， 这么做有几个问题：
- 自己写代码开发效率低
```
从开发而言，其基本的 Rewrite、Redirect 功能都需要重新开发，而一个稍微完备的静态资源服务器需要满足以下功能

cleanUrls(去除后缀),trailingSlash, rewrite, redirect, cache, cors

其中，Rewrite 的场景使用十分广泛，比如:

1. 单页应用中所有的 *.html 均为读取根目录 index.html

```

- 性能差, 试举一例，比如将文件系统修改为 ReadStream 的形式进行响应将会提升该静态服务器的性能，代码如下。

```
const server = http.createServer((req, res) => {
  // 此处需要手动处理下 Content-Length
  fs.createReadStream('./index.html').pipe(res)
})

```


这就是我们为何需要nginx， serve之类的专业静态资源服务的原因。


部署的简单理解： 部署，使得所有人都可以访问。 在一台拥有公共 IP 的服务器上，通过 npm start 运行代码，所有人都可访问他，即可视为部署成功。当然，公开给用户访问还需要域名；
> 实际上，有极少数小微企业在生产环境中就是直接 ssh 进生产环境服务器，并通过 npm start 部署成功后，通过 IP 与端口号的方式进行访问

#### 关于部署的几个问题

- 1. 问：那既然通过 npm start 可以启动服务并暴露端口对外提供服务，那为什么还需要 nginx 呢？

答： 你需要管理诸多服务(比如A网站、B网站)，通过 nginx 进行路由转发至不同的服务，这也就是反向代理，另外 TLS、GZIP、HTTP2 等诸多功能，也需要使用 nginx 进行配置。

当然，如果你不介意别人通过端口号去访问你的应用，不用 nginx 等反向代理器也是可以的；

- 2. 问：我确实不介意别人通过 IP:Port 的方式来访问我的应用，那在服务器可以 npm run dev 部署吗?

可以，但是非常不推荐。npm run dev 往往需要监听文件变更并重启服务，此处需要消耗较大的内存及 CPU 时间，导致性能问题。


- 3. 问：那为什么需要 Docker 部署？

用以隔离环境。

假设你有三个后端服务，分别用 Java、Go、Node 编写，你需要在服务器分别安装三者的环境，才能运行所有语言编写的代码，这对于开发者而言非常麻烦。

假设你有三个 Node 服务，分别用 node10、node12、node14 编写，你需要在服务器分别安装三个版本 nodejs 才能运行各个版本 nodejs 编写的代码，对于开发者而言也非常麻烦。

而有了 Docker，就没有这种问题，它可单独提供某种语言的运行环境，并同时与宿主机隔离起来。

对于前端而言，此时你可以通过由自己在项目中单独维护 nginx.conf 进行一些 nginx 的配置，大大提升前端的自由性和灵活度，而无需通过运维或者后端来进行。


## docker

docker 使应用部署更加轻量，可移植，可扩展。更好的环境隔离也更大程度地避免了生产环境与测试环境不一致的巨大尴尬。


底层原理: 

docker 底层使用了一些 linux 内核的特性，大概有 namespace，cgroups 和 ufs；

namespace： docker 使用 linux namespace 构建隔离的环境；

control groups： 限制资源配额，比如某个容器只能使用 100M 内存

ufs: UnionFS 是一种分层、轻量级并且高性能的文件系统， 支持对文件系统的修改作为一次提交来一层层的叠加


镜像:

镜像是一份用来创造容器的配置文件，而容器可以视作最小型的一个操作系统。



# 工程项目

# 1. 橙管家


橙管家由基座， 联邦模块， 和12个子应用组成，由分布在三个城市（北京，成都，杭州），分属于4个不同的前端团队的同学维护着。 基座，和联邦模块的变动会拉会分享， 有文档中心整理，长期维护，方便信息同步和记录。


### 固定表头(吸顶)

sticy 元素根据正常文档流进行定位，然后相对它的最近的滚动祖先 和 块级组件， 注意，一个sticky 元素会"固定“ 在离它最近的一个拥有”滚动机制“的祖先上。
但是 当滚动机制是不能是overflow\:hidden，或者overflow\:auto；（一般不生效需要检查一下祖先元素的overflow）

sticky属性仅在以下几个条件都满足时有效：

祖先级元素不能overflow\:hidden或者overflow\:auto属性；

必须指定top、bottom、left、right4个值之一，否则只会处于相对定位

父元素的高度不能低于sticky元素的高度


### 没有子元素的元素给固定内容占位（空白处css 占位）

比如表格里没有内容占位：

```
.ant-table-cell:empty:before {
    content: "--";
}


```

\:empty CSS 伪类 代表没有子元素的元素。子元素只可以是元素节点或文本（包括空格）,注释也算。否则就是空白。

### 表单改动后未保存离开时的弹窗提醒

方案： 离开时（浏览器刷新和关闭，路由切换），子应用判断内容是否变更，如果有变更需要设置一个全局状态即可，基座会根据子应用的状态进行弹窗拦截。设置一个sessionStorage状态,needBackTipStatus = 1; 为1时拦截，其余不拦截。（拦截后，弹窗确认关闭后，重置这个值）

#### 工程化体系梳理

##### 开发前

需求维护在同一的地方， 新建分支（基于oe）, 复杂项目要有设计文档

##### 开发中

编码：

1.  网络请求库统一
2.  公用组件库
3.  ui主题风格统一
4.  ts,lint, commit
5.  脚手架 - cra, umi
6.  node 版本统一
7.  统一npm 或者 yarn

前端后端服务交互：

1.  统一走一个网关

测试环境部署：

1.nginx 配置管理，各项目管理 ===> 统一管理
2\. 测试机器管理，多机器 ===> 统一一个机器

1.  需要多个测试环境 ===> 一套环境
2.  本地部署 ====> 走oe流水线，物理机部署
3.  从弹性云 ====> 研发云（不要钱，登录方便，好管理）

测试环境访问：

1.  多域名 ===> 单域名
2.  前端资源版本控制， 域名  ===> 分支
3.  h5 测试环境统一方案

cr 策略：

1.  何时cr。

回滚：

1.  回滚时机： 上线后出现故障，及时回滚
2.  如何回滚： 先odin 上回滚机器资源，然后oe上操作代码版本回滚
3.  回滚后： 确认线上环境回滚到稳定版本，检查git代码正确回滚

##### 开发后

质量监控：

1.  埋点数据分析 - omega, 天眼
2.  监控异常，监控报警 - 天眼， sentry,  关注： js错误率， api接口成功率， 首屏时间
3.  技术复盘： 技术实现，结果，todo; 现象描述，影响定级，时间轴，原因分析，教训

#### 性能优化

##### 首屏加载时间

##### 找问题

分析瀑布流，找出性能瓶颈

以下是基座资源加载顺序及时间：

基座html 60ms

开始时间 100ms:

第三方库 cdn  1000ms
base main.js  640ms
版本提示 270ms
机器人插件 1200ms

开始时间 1400ms:

打印wasm 5860ms
联邦模块 rmoteEntry.js 90ms
联邦模块资源 290ms

开始时间 1560ms:

login 接口 280ms
基础数据接口 600ms

开始时间 2700ms:

埋点配置apollo  和 config.json  70ms

开始时间 2830 ms:

子应用 manifest 170ms

开始时间  3150ms:

加载子应用资源

开始时间  3320ms:

tree list 接口

然后是业务接口；

问题： 在网络较好的情况下，加载子应用的manifest 已经用时3s，整个页面初始化展示出来约5s 多；

目前可优化点：

1.  机器人插件耗时1s多， 且阻塞后续渲染流程， 可以把机器人插件加载时机滞后到子应用加载完成
2.  将子应用配置写死在基座，可减少config请求
3.  现在加载子应用 await login 等基础接口，可以提前请求manifest ,待login 接口完成后再loading子应用。

##### 基座优化

1.  水印加载时机过早，后置

&#x20; 等第一个子应用挂在之后，再通过脚本动态挂载script 标签接在水印js

1.  dns 解析  prefetch

&#x9;使用 \<link rel="dns-prefetch" href=""> 进行dns 预解析， //zone.chengxinyouxuan.com  //s3-gzpu.didistatic.com,  在基座调整， 把域名放入href里：

```
<link rel="dns-prefetch" href="//zone.chengxinyouxuan.com"> 
<link rel="dns-prefetch" href="//s3-gzpu.didistatic.com">

```

1.  login 接口 和子应用load 是否可并行
2.  菜单权限接口两个合并为一个
3.  联邦模块remoteEntry 线上环境只初始化一次
4.  子应用通用配置写死在基座中

##### 子应用优化

1.  子应用路由按需加载， 各子应用全部按需加载，每一个模块单独打包，降低资源大小，与请求时间

方案 修改routes, 保证个route 唯一性， 修改方式： /*webpackChunkName:'唯一标识xxx'*/

```
{
    path: '/finance',
    exact: true,
    conponent: lazy(()=>import(/*webpackChunkName:'finance'*/ '@/pages/finance')),
    name: '应付管理'，
    selectKey: '/finance'
}



```

效果： js请求时间下降 500ms ， css请求时间下降 740ms

1.  删除无用代码可以减少请求体积，提高资源请求速度（随着需求变动，会或多或少出现已迭代或者启弃用的代码，在构建编译后加重代码包的体积）

效果： 删除后总包体积减少约42k, 请求下载时间大约缩减126ms

1.  后端（网关）接口gzip压缩

采用gzip后， size缩减 299.4k, 时间缩短1165ms

> 有请求头 Accept-Ecoding: gzip, deflate, br 不知道是不是？加了gzip 之后的效果。
> 有响应头 Content-Ecoding: gzip
> 我看大部分接口都加了，应该是的， 后续搜索确认一下。

1.  entry-manifest.json 子应用配置的请求合并

问题： 从目前基座的逻辑来看，必须要等到所有的子应用 entry-manifest.json 请求完毕之后才会挂载子应用进行渲染，如果一个子应用配置请求时间是200ms，那么总耗时需要800-900ms, 可能会造成白屏；

解决方案： 写一个webpack 插件， 合并manifest资源， 并上传cdn 进行更新，子应用只需要npm 引入即可

效果： 在本地运行时（真是效果需要打包线上测试）， 浏览器的fcp(首次内容绘制)时间减小1s

1.  监控

    1.  体验类埋点如： 体验指标统计，第一次加载子应用等
    2.  生命周期埋点： 子应用注册/挂载，页面加载
    3.  异常埋点： 接口异常， 资源异常， 白屏
    4.  多tab下子应用内部页面白屏
    5.  左侧菜单渲染耗时
    6.  页面内部内容区渲染统计
    7.  页面可交互时长统计

### 加水印

### 代理商专项改造

#### 整体改造点

1.  src/index.tsx删除对antd 样式的引用（子应用统一使用基座引用的这个样式）， 有的子应用使用了按需加载的antd样式，也需要删除
2.  子应用和基座 webpack 配置externals 字段， 打包时配出基座的cdn已加载的依赖

> webpack 对包的直接引用才会处理，引用的是里面的包是不会排除的，比如： import 'antd/es/select'

```
 externals: {
      reat:'React',
      antd: 'antd',
      moment: 'moment',
      'react-dom': 'ReactDoM',
      lodash: '_',
      qs: 'Qs',
      axios: 'axios',
    },

```

#### 请求函数request 改动

1.  baseUrl 取值逻辑修改： 本地开发自己切换网关服务，基座环境下直接从localStorage中取来用

```
// 从基座中取

baseUrl = parocess.env.NODE_ENV === 'development' ? defaultApiMap.development: JSON.parse(localStorage.getItem('micro_base_data')).gateway;

// 子应用本地开发时， 手动切换 网关服务

const defaultApiMap = {
    development: '//sim-222-test-zone.xxx'
}

```

#### 子应用类名的全局处理，避免冲突

```
改动前是cra 的默认配置

{
              test: cssModuleRegex,
              use: getStyleLoaders({
                importLoaders: 1,
                sourceMap: isEnvProduction
                  ? shouldUseSourceMap
                  : isEnvDevelopment,
                modules: {
                  mode: 'local',
                  getLocalIdent: getCSSModuleLocalIdent,
                },
              }),
            },
            
            
改动后，是改getLocalIdent 这一项的属性：getLocalIdent 是css-loader的配置默认为undefined，值为一个function，可以自定义生成的类名（自己设置类名规则，比如给每个类名加一个标记字段）,即使是css文件，不是.module.css文件，修改modules里的配置也是一样的

getLocalIdent: (context, localIdentName, localName, options) => getCSSModuleLocalIdent(context, localIdentName, 'base_'+localName, options)

给类名加了个前缀，base是定义的子应用名字；

之后写样式文件，全部写成模块的方式， xxx.module.csss/less/scss， 当前存在的不是modlue形式的样式文件在之后的修改中慢慢进行替换，逐渐淘汰，本期不错修改。

```


#### 测试多环境管理-分支管理

##### 仓库代码改造

1.在项目根目录下，新增deploySim.sh 文件， 代码如下, 需要修改（替换）成自己的项目名mendian-base-new：

```
# 流水线分支名
BRANCH_NAME=$OE_BRANCH_NAME
# 流水线打包后项目的资源地址
PACKAGE_URL =$OE_ARTIFACTORY_URL
# 项目即将部署在机器上的资源地址， （到时候mendian-base-new这个目录下，就会有这个项目的多个 分支的资源， 再进入$BRANCH_NAME下，就是打包好的各种资源，比如 indes.html, entry-nanifest.json, 各种.js.map文件...）
BRANCH_FILE="/home/xioaju/wujie_work/boss_sim/mendian-base-new/$BRANCH_NAME"
# master 分支资源在机器上的地址
BRANCH_MATER_FILE="/home/xioaju/wujie_work/boss_sim/mendian-base-new/master"

echo "======= 开始部署测试环境 ======"
echo "package url is $PACKAGE_URL"

# 获取流水线打包后项目资源
wget -O output.tar.gz $PACKAGE_URL
# 解压
tar -xzf output.tar.gz

# 将项目即将部署在机器上的资源地址下的资源清空
rm -rf $BRANCH_FILE
# 重新创建即将部署在机器上的资源地址目录
mkdir -p $BRANCH_FILE
# 将解压后的资源拷贝到 机器上的资源地址目录下
cp -rf output/*  $BRANCH_FILE/

# 如果没有master资源目录,就拷贝一份到master 资源目录下
if [ ! -x $BRANCH_MATER_FILE]; then
  mkdir "$BRANCH_MATER_FILE"
  cp -rf output/* $BRANCH_MATER_FILE/
fi

echo '========== 部署测试环境成功 ======='
exit $?

```

1.  对build.sh 进行修改： 修改产物输出位置， 添加 deploySim.sh 到输出目录下， 统一将产物资源放在 \$OUTPUT\_DIR/ 下

```
echo "========= 1. 拷贝 build 文件 ====="

mkdir -p $OUTPUT_DIR

(
  cp -rf ./build/* $OUTPUT_DIR/
  cp ./deploySim.sh $OUTPUT_DIR/
) || { echo "======== 拷贝file ========="; exit 2; }

echo "======= 构建结束 ======="



完整build脚本：


#!/bin/bash

# 执行nvm 脚本， 统一node 版本
source ~/.nvm/nvm.sh
nvm install v14.17.5
nvm use v14.17.5

echo "=======当前目录 ======="
# 找到项目根目录，并进去
BASE_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
echo "$BASE_DIR"

echo "======当前分支====="
BRANCH_NAME=$OE_BRANCH_NAME

# 资源输出目录
OUTPUT_DIR=$BASE_DIR/output
# 清空资源输出目录
rm -rf $OUTPUT_DIR
# 创建资源输出目录
mkdir $OUTPUT_DIR
rm -rf node_modules
echo "=======安装npm依赖=====指定源"
npm install --registry=http://registry.npm.xiaojukeji.com
# 命令执行结果
INSTALL_RET=$?
if [ $INSTALL_RET -ne 0 ]; then
  echo "=======npm install failure ======"
  exit $INSTALL_RET
else
  echo "=======npm install success ===="
fi

echo "======= 编译代码 ====="
npm run build

BUILD_RET=$?
if [ $BUILD_RET -ne 0 ]; then
  echo "=======npm build failure ======"
  exit $BUILD_RET
else
  echo "=======npm build success ===="
fi


echo "=======1. 拷贝build 文件 ====="
mkdir  -p  $OUTPUT_DIR
(
  cp -rf ./build/* $OUTPUT_DIR/
  cp  ./deploySim.sh $OUTPUT_DIR/
) || { echo "======拷贝file====="; exit 2;}

echo "====构建结束===="


# 前端构建，就是在项目根目录安装依赖，然后运行npm run build 打包,然后把打包产物拷贝到指定的资源输出目录

```

1.  webpack.config 配置修改

修改publicPath， publicPath 输出路径修改（对已有的西安航输出路径不影响， 测试环境时，输出到 entryManifestMap\['sim'], process.env.OE\_BRANCH\_NAME 为 OE 构建时默认注入的变量获取当前分支名

```
const entryManifestMap = {
  sim: `//boss-sim.chengxinyouxuan.com/mendian-micro-salestore-new/${process.env.OE_BRANCH_NAME}/`,
};
const publicPath = isOEProduction ? giftOssPublicPath : (process.env.OE_BRANCH_NAME ? entryManifestMap['sim']: '/')


```

entry.manifest.json 文件输出路径修改， publicPath 值和 entrypointFiles 中前缀为上面配置的publicPath，主要改动再cra的默认webpack 配置ManifestPlugin中， ManifestPlugin的作用是生成一份资源清单的json文件。

修改ManifestPlugin

ManifestPlugin改动点如下：

```
new ManifestPlugin(
  {
    fileName: 'entry-manifest.json',
    publicPath,
    generate: (seed, files, entrypoints) => {
      // ...
      const entrypointFiles = entrypoints.main.filter(fileName => !fileName.endsWith('.map')).map(item=>`${publicPath}${item}`)
      // ...
      return {...}
    }
  }
)

```

cra 的默认配置为：

```
new WebpackManifestPlugin({
        fileName: 'asset-manifest.json',
        publicPath: paths.publicUrlOrPath,
        generate: (seed, files, entrypoints) => {
          const manifestFiles = files.reduce((manifest, file) => {
            manifest[file.name] = file.path;
            return manifest;
          }, seed);
          const entrypointFiles = entrypoints.main.filter(
            fileName => !fileName.endsWith('.map')
          );

          return {
            files: manifestFiles,
            entrypoints: entrypointFiles,
          };
        },
      }),

```

然后又加了一份资源清单的配置：

```
new WebpackManifestPlugin({
        fileName: 'entry-manifest.json',
        generate:(seed, files, entrypoints) => {
          const manifestFiles = files.reduce((manifest, file) => {
            manifest[file.name] = file.path;
            return manifest;
          }, seed);

          const entrypointFiles = entrypoints.main.filter(fileName => !fileName.endsWith('.map') && !fileName.endsWith('.hot-update.js')).map(item=>`${publicPath}${item}`)

          const scripts = entrypointFiles.filter(item=>item.endsWith('.js'));
          const styles = entrypointFiles.filter(item=>item.endsWith('.css'));

          return {
            files: manifestFiles,
            entrypoints: entrypointFiles,
            scripts,
            styles,
          }
        }
      }),


```

1.  最终我们是通过在location 中携带search 参数 ?branch=branch\_name , 以分支名来做前端资源版本隔离的， 实现前端多环境。 所以子应用中在做一些页面跳转的时候记得别把search 参数丢了。 因为我们的系统都是hash路由， 所以对hash 后面的参数并不会有影响。主要包括以下几种跳转场景：

```

a. window.open 使用场景， 在url 里把search 加上
b. history.pushState 使用场景， ， 在url 里把search 加上
c. 对跳转路径path， 同理；



```

1.  oe 流水线配置

在oe中， 设置 ==> 流水线模版 中， 分别对分支和主干模版编辑

a. 分支模版改造， 在打包编译完结后，增加一个新节点， 执行deploySim.sh 脚本，进行物理机部署（测试环境）
b. 主干模版改造，在确认上线阶段后，增加master测试部署 新节点。 master 测试部署节点，和a步骤中一致。 （在测试机中增加一份master 稳定线上版本资源）
c. 在主干模板odin上线前的 构建编译 节点， 增加环境变量： OE\_BUILD\_ENV=production

1.  nginx 规则配置， 配置nginx 转发规则

在/etc/nginx （配置文件存放目录）下有两处配置文件， conf.d 文件   和 nginx.conf 文件（主配置文件）

> 安装Nginx之后发下配置文件只有一个/usr/local/nginx/conf/nginx.conf, 所有的配置包括虚拟主机也要在此文件中配置，这样虚拟主机多了就会不方便管理。
> 在/usr/local/nginx下创建conf.d文件夹，在文件夹下创建对应的域名配置文件, 在原来的配置文件/usr/local/nginx/conf/nginx.conf的http块下加一句：`include /etc/nginx/cong.d/*.conf`

在conf.d 文件下，有各个项目的配置文件， 橙管家的是： boss-sim-new\.conf

文件内容如下：

```
server {
  server_name boss-sim.chengxinyouxuan.com;
  listen 9091;

  set $projectPath mendian-base-new;

  root /home/xiaoju/wujie_work/boss-sim/$projectPath/;
  add_header 'Access-Control-Allow-Origin' '*';
  add_header 'Access-Control-Allow-Credentials' 'true';
  add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
  add_header 'Access-Control-Allow-Headers' 'Authorization,Accept,keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type';

  # 请求路径为/ 的匹配规则
  location / {
    set $branch 'master';
    # 如果GET请求中变量名branch参数的值， 与正则表达式.+ 不区分大小写匹配， 即：如果get请求中带有branch参数, 就把参数赋值给branch 变量
    if( $arg_branch ~* .+){
      set $branch $arg_branch
    }
    set $current_branch_file "/home/xiaoju/wujie_work/boss-sim/${projectPath}/${branch}";
    # 如果$current_branch_file 不存在
    if(!-e $current_branch_file){
      set $branch 'master';
    }

    # 如果请求的文件路径以htm或者html 结尾, 则添加no-cache头
    if($request_filename ~ .*\.(htm|html)$){
      add_header Cache-Control no-cache;
      root /home/xiaoju/wujie_work/boss-sim/$projectPath/$branch;
    }
    
    # 如果文件路径不存在或者不是文件
    if(!-f $request_filename){
      root /home/xiaoju/wujie_work/boss-sim/$projectPath/$branch;
    }

    index index.htm index.html;
    # 尝试查找文件
    try_files $uri $uri/ /inde.html;
  }

  # 请求路径为/mendian-micro-promise-new 的匹配规则， 基本与上面类似
  location /mendian-micro-promise-new {
    if(!-f $request_filename){
      rewrite /mendian-micro-promise-new/(\S+)/(.*) /mendian-micro-promise-new/master/$2 last;
    }
    # location匹配访问的path目录下的文件直接是在alias目录下查找的
    alias /home/xiaoju/wujie_work/boss-sim/mendian-micro-promise-new;
    index index.htm index.html;
  }

  # 其他应用的匹配规则也一样配置
}

```

nginx.conf 里内容如下：

```
user root;
worker_process auto;
error_log /var/log/nginx/error.log;
pid /run/nginx.pid;

include /usr/share/nginx/modules/*.conf;

events {
  worker_connections 1024;
}

http {
  log_format main '$remote_addr - $remote_user [$time_local] "$request"'
                  '$status $body_bytes_sent "$http_referer"'
                  '"$http_user_agent" "$http_x_forwarded_for"';
  gzip on;
  gzip_static on;
  gzip_comp_level 6;
  gzip_vary on;
  gzip_types text/plain application/javascript text/css;

  access_log /var/log/nginx/access_log main;

  sendfile on;
  tcp_nopush on;
  tcp_nodelay on;
  keepalive_timeout 65;
  types_hash_max_size 2048;

  include /etc/nginx/minme.types;
  default_type  application/octet-stream;

  # server 的配置放在conf.d里
  include /etc/nginx/conf.d/*.conf;
  
}

```

1.  测试机器过期资源清理，每次部署基座时清理超过15天没有改动的分支资源

在基座的部署脚本deploy.sh里,  执行机器上的清理脚本：

```
...

CLEAN_EXPIRE_BRANCHS="/home/xiaoju/wujie_work/boss-sim/branchAutoClean.sh"


...
# master 部署时触发脚本清理虚拟机上过期分支（近15天未部署过的分支）
if [$BRANCH_NAME == "master"]; then
  chmod -R 777 $CLEAN_EXPIRE_BRANCHS
  sh $CLEAN_EXPIRE_BRANCHS
fi

```

机器上的branchAutoClean 脚本内容如下：

```
cd /home/xiaoju/wujie_work/boss-sim
deletefile=/home/xiaoju/wujie_work/boss-sim
oefile=/root/oe

# 循环boss-sim下的文件
for delete_project in `ls ${deletefile}`
do 
# 如果是目录 并且 以mendian开头 (橙掌柜的项目都以mendian开头)
 if [-d $deletefile/$delete_project] && [[ $delete_project =~ ^mendian.*]]
 then
  # 项目的完整路径
  project_path=$deletefile/$delete_ project
  echo "project_path $project_path"
  # 找出项目下超过15天未更新的（项目下就是各个分支资源了）
  # 向下找0层， 除了$project_path/master之外的，类型为目录的，文件更改时间大于15天的
  find $project_path/* -maxdepth 0 -path $project_path/master -prune -o -type d -mtime +15 -exec rm -rf {} \;
  fi
done

if [-d  $oefile];then
echo "/root/oe is exit"
rm -rf /root/oe
fi


```

补充知识：

nginx 中if语句中的判断条件：

1.  正则表达式匹配

\==:~：与指定正则表达式模式匹配时返回“真”，判断匹配与否时区分字符大小写；
~*：与指定正则表达式模式匹配时返回“真”，判断匹配与否时不区分字符~：与指定正则表达式模式不匹配时返回“真”，判断匹配与否时区分字符大小写；
!~*：与指定正则表达式模式不匹配时返回“真”，判断匹配与否时不区分字符大小写；

1.  文件及目录匹配判断

\-f, !-f：判断指定的路径是否为存在且为文件；
\-d, !-d：判断指定的路径是否为存在且为目录；
\-e, !-e：判断指定的路径是否存在，文件或目录均可；
\-x, !-x：判断指定路径的文件是否存在且可执行；

1.  全局变量

`$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成
$`uri ： 不带请求参数的当前URI，\$uri不包含主机名，如/foo/bar.html  , 即不带域名和参数

1.  Try\_files规则

try\_files `$uri $`uri/ /index.php
假设请求为<http://www.qq.com/test，则$uri为test>

查找/`$root/test文件
查找/$`root/test/目录
发起/index.php的内部“子请求”

nginx 参考： <https://www.cnblogs.com/robinunix/p/12843815.html>

# 多环境

使用葛豪的ppt总结

针对测试环境。每一项表示一页ppt

#### 1.测试环境服务调用（看不懂，已拍照）

#### 2. 测试环境前端服务

1.  最开始是，多域名的（有限的多套测试环境，靠域名区分），多机器的，一个域名对应着一个机器。
2.  然后变成，多域名，单机器的，多个域名指向一个机器
3.  最后变成，所有子应用统一使用一个域名（无限的多套测试环境，靠分支名区分），一个机器

#### 3. b端前端测试环境域名治理解决的痛点

实际业务开发中我们常常遇到以下痛点：

1.  测试时沟通成本大

测试用哪套环境，环境域名是啥？
sim01 什么时候能释放， sim01 环境又被谁覆盖了？
你用公共分支部署了么？
前端环境不够用了。

1.  新起一个子应用的流程复杂测冗长

要申请搞多套测试环境，申请多个测试域名和机器

> 线上，和pre，之前也是一个子应用搞了一套域名，其实没必要，后来橙管家，只用一个节点，一套域名，在odin节点下新增模块就可以了。不过和测试多环境主题关系不大就不在这里展开了

多域名多机器现状是面临的问题:

1.  容易被覆盖，沟通成本高
2.  前后端环境强耦合，前端sim01 测试环境， 也会访问后端的sim01域名
3.  想新增一套测试环境成本大， 需要处理机器，域名，nginx
4.  多套测试域名管理不便
5.  开发，测试体验不友好

#### 前端测试环境统一： 单环境  单域名

方案一：单环境 单域名 (方案一不太懂)（已拍照）

多个开发分支， f\_a, f\_b,  对应一个测试环境， 有资源 版本f\_a, f\_b,  访问入口是  `test.chengxinyouxuan.com/f_a.html, test.chengxinyouxuan.com/f_b.html`

静态资源形式 ， index.2b413f.js， index.2b413f.css;    index.h867j2.js， index.h867j2.css;

解决的上面所说的痛点问题， 起到了降本提效的作用；

但是也存在如下问题：

1.  依赖项目hash 打包  （这个不太懂，后续研究研究）
2.  不支持多入口文件访问（这个也不太懂）
3.  对路由跳转有入侵（这个也不太懂，感觉跟方案二差不多）
4.  机器内存会爆， 且老版本资源不易清理 （这个也不太懂，感觉跟方案二差不多）

方案二： 单环境  单域名（已拍照）

多个开发分支， f\_a, f\_b,  对应一个测试环境， 有资源 版本f\_a, f\_b,  访问入口是  `test.chengxinyouxuan.com/?branch=f_a, test.chengxinyouxuan.com/?branch=f_a`

相比二言，方案二，不依赖hash， 支持多入口， 而且不影响路由， 占用内存也少，易清理， 是我们真的最终选择方案。

#### 整体设计方案

编码部分： 创建分支f\_a, 用不同pulicPath来区分，开发、测试和生产环境的资源访问路径， 打包后生成产物dist。 并且在项目根路径下写个deploy.sh脚本。

oe流水线： 在oe流水线上oe 打包编译后，自动触发研发云部署，调用项目里的deploy.sh脚本部署。 odin确认上线后， 自动触发主干编译打包，自动触发研发云部署，调用项目里的deploy.sh脚本部署。

nginx：  站点访问域名时，请求到达nginx, 根据查询参数分支名，在server.conf丽来确定取哪里的资源（版本控制）

#### 结果与思考

思考： 前后端环境没必要一一对应。 前端资源版本控制？ 如何保证一套稳定的前端环境？

改造后的流水线：

创建oe分支/流水线， 本地开发调试， 然后编译打包， 测试环境部署（自动触发，解压/cp, 无需授权，独立资源，不会覆盖）， cr,   编译打包， odin, 确认上线， 编译打包， 稳定测试环境部署

治理结果：

1· 覆盖系统5个，
2\. 节省域名，机器资源30+，

1.  开发提效，独立环境，自动部署
2.  测试提效，一套环境，互不干扰
3.  余味提效，唯一域名，一次配置
4.  独立稳定的前端环境


### monorepo

单仓库巨石应用演变到：
    - monorepo 为了组合， 模块仓库达到一定数量级，不好统一管理，代码复用困难
      - 中大型项目，多模块项目，项目之间关联性强，更适合用 MonoRepo 方式管理代码
    - 微前端为了拆分，模块解耦，降低了巨石应用的复杂度，每个模块都可以独立编码、测试、发版，代码管理变得简化，构建效率也得以提升
      - 中大型项目，模块没那么多，关联性没那么强


#### pnpm

pnpm解决的问题：主要解决了两个问题

- 1. 解决幽灵依赖问题
  - npm/yarn 安装依赖时，存在依赖提升，某个项目使用的依赖，并没有在其 package.json 中声明，也可以直接使用，这种现象称之为 “幽灵依赖”（间接依赖）；随着项目迭代，这个依赖不再被其他项目使用，不再被安装，使用幽灵依赖的项目，会因为无法找到依赖而报错。
2. 节省磁盘空间，安装依赖耗时长 
  -  问题： MonoRepo 中每个项目都有自己的 package.json 依赖列表，随着 MonoRepo 中依赖总数的增长，每次 install 时，耗时会较长。
     -  相同版本依赖提升到 Monorepo 根目录下，减少冗余依赖安装；使用 pnpm 按需安装及依赖缓存

#### 构建打包耗时长的问题处理

  问题：多个项目构建任务存在依赖时，往往是串行构建 或 全量构建，导致构建时间较长

  方案：增量构建，而非全量构建；也可以将串行构建，优化成并行构建。


## Monorepo 选型

  此类工具，*主要解决大仓库 Monorepo 构建效率低的问题*。
  - 项目代码仓库越来越庞大，工作流（int、构建、单元测试、集成测试）也会越来越慢；这类工具，是专门针对这样的场景进行极致的性能优化。适用于包非常多、代码体积非常大的 Monorepo 项目。

重型(构建型)Monorepo方案：

- 1. Turborepo 是 Vercel 团队开源的高性能构建代码仓库系统，允许开发者使用不同的构建系统。
- 2. Rush 是微软开发的可扩展的 Monorepo 工具及解决方案。
- 3. Nx 是 Nrwl 团队开发的，同时在维护 Lerna，目前 Nx 可以与 Learn 5.1及以上集成使用

两种轻量化 Monorepo 方案: Lerna,yarn workspace + Lerna

### 两种轻量化 Monorepo 方案
#### 1. Lerna

*Lerna 是 Babel 为实现 Monorepo 开发的工具: 最擅长管理依赖关系和发布*
Lerna 优化了多包工作流，解决了多包依赖、发版手动维护版本等问题
- Lerna 不提供构建、测试等任务，工程能力较弱，项目中往往需要基于它进行顶层能力的封装

Lerna 主要做三件事:
- 1. 为单个包或多个包运行命令 (lerna run)
- 2. 管理依赖项 (lerna bootstrap)
- 3. 发布依赖包，处理版本管理，并生成变更日志 (lerna publish)


Lerna 能解决了什么问题:
- 代码共享，调试便捷： 一个依赖包更新，其他依赖此包的包/项目无需安装最新版本，因为 Lerna 自动 Link
- 安装依赖，减少冗余：多个包都使用相同版本的依赖包时，Lerna 优先将依赖包安装在根目录
- 规范版本管理： Lerna 通过 Git 检测代码变动，自动发版、更新版本号；两种模式管理多个依赖包的版本号


Lerna 工作模式:

Lerna 允许您使用两种模式来管理您的项目：固定模式(Fixed)、独立模式(Independent)

-  固定模式（Locked mode）
   -  Lerna 把多个软件包当做一个整体工程，每次发布所有软件包版本号统一升级（版本一致），无论是否修改
   -  默认是固定模式
- 独立模式（Independent mode）
  - Lerna 单独管理每个软件包的版本号，每次执行发布指令，Git 检查文件变动，只发版升级有调整的软件包
  - 项目初始化时，lerna init --independent


Lerna 常用指令：
- lerna init: 执行成功后，目录下将会生成基础目录结构
- lerna create: 创建 package(子项目)
  ```
  # lerna create <name> [location]
  # 在 packages/pwd1 目录下，生成 package2 依赖包
  lerna create package2 packages/pwd1

  ```
- lerna add: 给 子项目 添加（安装）依赖
  - 安装的依赖，如果是本地包，Lerna 会自动 npm link 到本地包
- lerna bootstrap： 给所有 package 安装依赖
  - 会自动为每个依赖包进行 npm install 和 npm link 操作
- lerna exec: 给 package 执行 shell 指令
  ```
  # 删除所有包内的 lib 目录
  lerna exec -- rm -rf lib

  ```
- lerna run： 给 package 执行 scripts 指令
- lerna clean： 清除所有 package 下的依赖
- lerna publish： 发布软件包，自动检测
  - lerna publish主要做了:
  - 1. 运行lerna updated来决定哪一个包需要被publish
  - 2. 如果有必要，将会更新lerna.json中的version,并将将所有更新过的的包中的package.json的version字段更新
  - 3. 将包publish到npm上
- lerna diff: 查看自上次发布的变更


关于冗余依赖的安装：
- npm 场景下 lerna bootstrap 会安装冗余依赖（多个 package 共用依赖，每个目录都会安装）
  - 解决方案：
    - lerna bootstrap --hoist
- yarn 会自动 hosit 依赖包（相同版本的依赖，安装在根目录），无需关心


lerna init 目录下将会生成这样的目录结构：
    ```
    packages(目录)
    lerna.json(配置文件)
    package.json(工程描述文件)


    lerna.json 如下：

    {
      "version": "0.0.0",
      "useWorkspaces": true,
      "packages": [
        "packages/*",
      ],
    }

    需要在项目根目录下的 package.json中设置 "private": true

    {
      "name": "xxxx",
      "version": "0.0.1",
      "description": "",
      "main": "index.js",
      "private": true,
      "scripts": {
        "test": "echo "Error: no test specified" && exit 1"
      },
      "keywords": [],
      "author": "",
      "license": "ISC",
      "devDependencies": {
        "lerna": "^6.4.1"
      },
      "workspaces": [
        "packages/*"
      ]
    }
    ```

### 2. yarn workspace + Lerna

前情：

yarn 1.x 及以上版本，新增 workspace 能力，不借助 Lerna，也可以提供原生的 Monorepo 支持，需要在根目录下 package.json 中，声明 workspace

```
{
  "private": true, // 必须是私有项目
  "workspaces": ["project1", "project2/*"]
}

```

yarn workspace VS Lerna:
- yarn workspace 更突出对依赖的管理： 依赖提升到根目录的 node_modules 下，安装更快，体积更小
- Lerna 更突出工作流方面：使用 Lerna 命令来优化多个包的管理，如：依赖发包、版本管理，批量执行脚本

yarn workspace 和 Lerna 各有所长，yarn workspace + Lerna 是更好的 Monorepo 方案，执行命令 yarn（相当于执行 lerna bootstrap），即可安装所有依赖，指令过渡更平滑，自动依赖提升，减少依赖安装。

能力分工：
- Lerna 将依赖管理交给 yarn workspace；
- Lerna 承担依赖发布能力。


操作步骤：
- 1. 配置 Lerna 使用 Yarn 管理依赖：learn.json 中配置 "npmClient": "yarn"
- 2. 配置 Lerna 启用 Yarn Workspaces：
  - 1. 配置 lerna.json/useWorkspaces = true
  - 2. 配置根目录 package.json/workspaces = ["pacages/*"] , 此时 lerna.json 中的 packages 配置项将不再使用
  - 3. 配置根目录 package.json/private = true
  - 上面三个配置项需同时开启, 只开启一个 lerna 会报错: 此时执行 lerna bootstrap 相当于执行yarn install，等同于执行 lerna bootstrap --npm-client yarn --use-workspaces
    - 由于 yarn 会自动 hosit 依赖包, 无需再 lerna bootstrap 时增加参数 --hoist (加了参数 lerna 也会报错)


#### 3. Lerna + pnpm + workspace

pnpm 是新一代 Node 包管理器，它由 npm/yarn 衍生而来，解决了 npm/yarn 内部潜在的风险，并且极大提升依赖安装速度;
pnpm 内部使用基于内容寻址的文件系统，来管理磁盘上依赖，减少依赖安装；

pnpm 相比于 npm、yarn 的包管理器，优势如下，同理是 Lerna + yarn + workspace 优势：
- 装包速度极快： 缓存中有的依赖，直接硬链接到项目的 node_module 中；减少了 copy 的大量 IO 操作
- 磁盘利用率极高： 软/硬链接方式，同一版本的依赖共用一个磁盘空间；不同版本依赖，只额外存储 diff 内容
- 解决了幽灵依赖： node_modules 目录结构 与 package.json 依赖列表一致

pnpm 原理:
- 存储中心 Store 集中管理依赖：不同项目，相同版本依赖安装只进行硬链接；不同版本依赖，只增加Diff文件
- 项目 package.json 依赖列表，和node_modules/.pnpm目录结构一致
- 相同依赖安装时，将 Store 中的依赖硬链接到项目的 node_modules/.pnpm 下，而不是复制，速度快
- 项目node_modules中已有依赖重复安装时，会被软链接到指定目录下

建议采用渐进式架构方案，即对于轻量级 Monorepo 项目，我们初期可以选择 Lerna + pnpm workspace + lerna-changelog，解决了依赖管理、发版管理等问题，为开发者带来便利；随着后续项目迭代，代码变多或多个项目间依赖关系复杂，可以很平滑的接入 Nx 来提升构建打包效率。
