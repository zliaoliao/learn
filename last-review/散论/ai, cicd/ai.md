# 大模型的发展与理论基础

## 基础理论

### 注意力attion机制

注意力机制主要用途： 提取关键信息，忽略不相关的信息

注意力机制的特点和优势：
- 1. *注意力机制有助于克服循环神经网络（RNNs）的一些挑战，例如输入序列长度增加时性能下降，和顺序处理输入导致的计算效率低下*。
- 2. 在自然语言(NLP),计算机视觉（Computer Vision），跨模态任务和推荐系统等多个领域中，注意力机制已经成为多项任务中的最先进的模型，取得了显著的性能提升
- 3. 注意力机制被广泛用于提升神经网络的可解释性，帮助解释模型的决策过程，使得原本被认为是黑盒模式的神经网络变得更易解释。


在注意力机制中，“Q”、“K”和“V”分别代表什么： 查询、密钥和值

### word2vec 

word embedding

word embedding 是NLP 的深度学习的基础

word embedding把一个单词变成一个多维的，可以用于数学运算的向量。

后面又发展为，把一个短语，一句话，一个段落，变成一个多维的向量。


*embedding之于大模型的价值是规范化浅层语义提取*

### transformer


transformer 本身是提了一个网络结构，主要提供了语意理解的能力，基于注意力机制，它的seft-attion 能够分析出每句话内部各个字之间的联系，以及联系的强度。


## bert

### 预训练

bert的预训练类似完形填空。

把一段话，的15%的词做成mask, 这个mask可能是一个空，可能是一个错误的词（文不对题），也有可能是对的，然后机器利用上下文去学习，去补充，纠正这些mask；


理解了语意之后，针对特定的任务只需做少量的微调，标注


### bert 和 gpt 的差异 与共识

bert 和 gpt 的差异：

- 训练方式：
  - bert: 自编码
  - gpt: 自回归
- 预测目标
  - bert:给点上下文，预测其中的一个或者多个单词
  - gpt: 给定前面的单词，预测下一个单词
- 输入处理：
  - bert: 双向，同时考虑一个单词的左右上下文
  - gpt: 单向，从左到右，或者从右到左
- 适用场景及优缺点点：
  - bert: 适合理解上下文， 有助于信息提取，问答系统， 情感分析等；对上下文理解能力强，生成文本连贯性较弱
  - gpt: 适合生成式任务， 例如文章生成， 诗歌创作；预测连贯性较强， 对上下文理解能力相对较弱
- 架构：
  - bert: 基于transformer 的编码器
  - gpt: 基于transformer 的解码器
- 语言模型：
  - bert: 判别式
  - gpt: 生成式
  


bert 和 gpt 的共识：

模型架构： transformer
数据预处理： 都需要对数据进行Tokenization, 一般使用词片方法（Subword Tokenization）
模型训练： 均使用大量无标签数据进行预训练
任务迁移： 都可以通过fine-tuning方式进行任务迁移
训练目标： 都试图通过预训练理解语言的一般模式， 如语法，语义，上下文关系等
多语言支持： 均支持多语言模型训练


## gpt(Generative Pre-trained Transformer)

### 自然语言处理的发展

- 1. 人工规则： 1990年前
  - 代表性成果： 基于手工设计的规则系统
  - 数据规模： 少量规则集
  - 技术栈： 基于专家知识和规则系统设计
- 2. 统计机器学习： 1990-2012
  - 代表性成果： HMM, CTF...
  - 数据规模： 百万级标注数据
  - 技术栈： 统计机器学习算法
- 3. 深度学习： 2013-2018
  - 代表性成果： Encoder-Decoder, Word2vec, Attention
  - 数据规模： 十亿级标注数据
  - 技术栈： 深度学习网络+框架
- 4. 预训练： 2018-2020
  - 代表性成果： Transformer, ELMo, bert, gpt1,gpt2,gpt3
  - 数据规模： 数千亿级*未标注*数据
  - 技术栈： pre-training + fine-tuning(微调)
- 5. 大语言模型： 2020-至今
  - 代表性成果： gpt3.5, gpt4
  - 数据规模： 更大规模的用户数据(有了用户反馈)
  - 技术栈： instruction-tuning, prompt-tuning, rlhf


### 预训练语言模型的三种网络结构（2018-2020）

Encoders(编码器): 编码器主要用于处理和理解输入信息。这些模型可以获取双向上下文， 即可以同时考虑一个词前面和后面的信息。由于编码器可以考虑到未来的信息，他们非常适合用于需要理解整个句子的任务，如文本分类， 命名实体识别等；bert就是一种典型的预训练编码器。

Decoders(解码器)： 解码器主要用于生成输入信息。他们是语言模型的基础，用于预测下一个单词， 解码器只能考虑过去的词，而不能考虑未来的词，这使得他们非常适合与生成任务， 如文本生成，对话系统等；gpt就是典型的预训练解码器；

Encoder-Decoders(编码器-解码器)：编码器-解码器结构结合编码器和解码器的优点。如何预训练编码器-解码器模型是一个开发性问题，因为需要考虑到如何有效使用编码器-解码器的特点， T5和BART都是典型的预训练编码器-解码器模型


### gpt的发展

gpt1 : *GPT-1的主要目标是通过生成式预训练来提升语言理解能力*
  - 把transfomer 的 干到了12层
  - 参数： 1.1亿
  - 进行更大规模的训练，预训练数据集： 书籍和英语维基百科
  - 主要贡献： 1. 提出了基于生成式预训练语言的理解方法（预训练做的好，下游只需要微调，就能达到很好的效果） 2. 展示了预训练语言模型在多种下游任务的性能提升

gpt2 : *GPT-2在模型规模上进行了提升，以提高其处理复杂任务的能力*
- 把transfomer 干到了48层
- 参数： 15亿
- 进行更大规模的训练，预训练数据集：更多的书籍， 英语维基百科
- 主要贡献：1. 提出了无监督多任务学习的语言模型（把fine-tuning再训练时一起学了）  2. 扩展了模型规模和训练数据集规模

gpt3 : *GPT-3的主要创新是引入了在少量样本上的学习能力*
- 把transfomer 96层
- 参数： 1750亿
- 进行更大规模的训练，预训练数据集：增加了互联网的数据（Common Crawl）， 更多的书籍，英语维基百科
- 主要贡献：1. 引入了少样本学习的能力 2. 提出了prompt engineering 3. 进一步增大了模型规模和训练数据集规模



gpt3模型更大了，加了1750亿的参数，虽然效果不错，但是模型太大，已经不方便随意做微调了， gpt3提出一个非常重要的观点: in context learning(在上下文中学习)， 这个观点出来后使得我们今天去学习和使用大语言模型，进入一个新的高度。怎样在不改变模型的前提下去拿到想要的结果，这也是prompt的前身。

从gpt3开始， gpt该学的都已经学会了， 这时候与语言模型沟通就成为一个重要的技能， 你的说清楚你想要大模型干啥， 基于gpt3的aigc公司很多那是从那个时候开始的，甚至产生了prompt工程师；


gpt4模型更大了，参数上万亿： *GPT-4的主要创新是在语言模型的基础上，引入了图像识别的能力，使其可以处理多模态任务*





关键概念：

in-context-learning: 在给定的上下文中，使用新的输入，来改善模型的输出，通过提供具有特定格式或者结构的示例输入，使模型能够生成输出时利用这些信息；关注的是利用序列中的上下文信息来影响模型的输出

prompt-learning: 模型被训练以响应特定的提示。在这种情况下， 提示是模型输入的一部分， 它指导模型产生特定类型的输出。关注的是如何通过设计有效的提示龙引导输出。

few-shot learning: 少样本学习是指用极少量的标注样本来训练机器学习模型的技术， 在gpt3中少量样本学习的实现方式是向模型提供少量的输入-输出示例， 这些示例作为对话的一部分， 描述了模型应该执行的任务。

prompt Engineering: 提示工程师指设计和优化模型的输入提示，来改善模型的输出。在大型语言模型中，如何提问或者构造输入的方式， 可能对模型的输出有重大影响。因此，选择正确的提示对于获取有用的输出十分重要。


### gpt 赢在哪里

gpt3，gpt3.5, gpt4 的大部分训练数据都截止在2021年， 当然后续线上用户的反馈也会作为它fine-tunning的一部分， 基本上无限制的去堆数据基本已经到头了。

在gpt的演进过程中， OpenAi 采用了一系列的训练策略，这包括基础的大规模预训练， 也包括后续的指令微调等方法。

- 预训练（pre-trained）： 大规模预训练是为了使模型获取丰富的语言知识和理解能力。在预训练过程中， 模型通过大量无标签数据来学习语言的基础知识， 这一过程主要是依赖无监督学习。
- 指令微调（Instruction-tuning）: 在预训练模型的基础上， 通过针对任务的标注数据进行微调， 使模型能够在特定任务上的表现得到提升。同时，通过对微调数据的静心设计和选择， 还能够引导模型按照人类的的预期来执行任务。这一过程， 主要依赖有监督学习。微调的数据量很小，因此微调不是为模型注入新知识，而是*激发和引导模型利用已有的知识来完成特定任务*。（这个微调就是大语言模型的核心竞争力）


而像新产生的数据，短视频等，大多还没有被用起来，这也是gpt4的重要工作


初始gpt3内部命名为davinci, 它分化出两条路线用来迭代gpt3模型：
- 1. training on code: code-davinci-001, 让模型去学代码， 人类产生了如此多的代码不得学学，学完代码后模型的推理能力开始涌现了（从结果上来看，是代码本身写的时候，面向对象，面向过程的方式，给它增加了这方面能力）
- 2. Instruction-tuning: 指令微调

然后把上面两条路线的技术手段合二为一，训练出来的模型code-davinci-002, 也就是gpt3.5, 然后又训练了人类指令响应（RLHF）：
- 3. 人类指令响应（RLHF）： 新模型能针对特定的指令生成更恰当的回应， 而非回复训练集中频繁出现的无关句子。

### gpt4 一个新的开始

2022年8月，gpt4训练完成， 23年3月， openai 发布gpt4,相比3.5它有如下优势和提升：

- 1. 多模态模型： gpt-4支持图像输入， 出色的视觉信息理解能力是的gpt4能对接多样化的下游任务。文本理解能力，多轮对话能力也更强。
- 2. gpt+生态： 借助gpt4强大的能力， 依托chatgpt plugin 搭建aigc 应用生态商店（类似app store）
- 3. 应用+gpt: gpt4已经被应用在多个领域，包括微软office, duolingo, khan academy等
- 4. 扩展上下文窗口： gpt4 and gpt-4-32k 分别提供了最大长度为8192 和  32768个token的上下文窗口， 这使得gpt4可以通过更多的上下文来完成更复杂的任务， 也为思维链（CoT）, 思维树（ToT）等后续工作提供了可能。


## 提示学习 prompt-learning

in-context-learning: 在给定的上下文中，使用新的输入，来改善模型的输出，通过提供具有特定格式或者结构的示例输入，使模型能够生成输出时利用这些信息；关注的是利用序列中的上下文信息来影响模型的输出

prompt-learning: 模型被训练以响应特定的提示。在这种情况下， 提示是模型输入的一部分， 它指导模型产生特定类型的输出。关注的是如何通过设计有效的提示龙引导输出。（是把大模型用好的工程化的手段）

大模型和用户有点类似，两个沟通能力不强的人如何做有效交流，一个是提高大模型的理解能力，另外一个方法就是描述清楚需求，这里prompt 是关键，让我们的任务描述的更适合大语言模型去理解

## prompt的理论支撑：

### 思维链（chain-of-thought prompting, CoT）

*思维链是一种激励大型语言模型进行推理的提示方法*


思维链（CoT）的特点：

- 1. 思维链允许模型将一个问题分解为多个中间步骤， 这意味着可以将额外计算资源分配给需要更多推理步骤的问题。
- 2. 思维链提供了对模型行为的可解释窗口， 提示了它是如何得到特定答案的， 并提供了调试推理路径错误之处的机会
- 3. 在数学题， 常识推理， 符号操作等任务中都可以使用思维链推理，原则上适用于任何人类能够通过语言解决的任务。


当模型足够大的时候才容易引发思维链。

Cot思维链提示词黑魔法： Think step-by-step; 在你的问题后面加上这句话，提示大模型一步一步的拆解思考，有更大机会得到正确的答案。

通过思维链，我们可以看出大语言模型的强于弱：
- 强在， 随着模型规模的提高，让语义理解，符号映射，连贯文本生成等能力跃升， 从而让多步骤推理的思维链成为可能， 带来“只能涌现”
- 弱在， 即使大语言模型表现出前所未有的能力，但思维链暴露了它，依然是鹦鹉学舌， 而非真正产生了意识


### 自洽性（self-consistency, CoT-SC）:多路径推理

通过自洽性提高了思维链推理的能力，多条路径去推理问题， 得到各自的答案，然后做综合处理。*自洽性是一种提高模型推理能力的技术*

### 思维树（Tree-of-Thoughts）: 续写佳话

遍历所有的可能答案， 找到一条全局最优解。
*思维树是一种引导模型解决问题的提示方法*


ToT工作原理解读：

- 1. 思维分解： ToT利用问题属性来设计和分解中间思维步骤， 也就是把问题拆解为树的一个个节点。
- 2. 思维生成： 定义思维生成器G(p, s, k), 给定一个树状态， 我们考虑两种状态为下一个思维步骤生成k个选项：
  - 1. 从思维链提示中独立同分布的抽样思维。 当思维空间丰富时， 独立同分布的样本能够带来多样性
  - 2. 使用“提议提示”逐个提出思维， 当下一个思维空间更受限时（可选择性变少），在相同的语境中提出不同的想法可以避免重复。
- 3. 状态评估： 
  - 已经拿到了不同状态的前沿， 状态评估器评估他们解决问题的进展情况， 确定哪些状态继续探索， 以及以何种顺序进行的启发式方法。利用大语言模型本身的推理能力，对这些状态进行评估，去决定如何继续进行搜索。
- 4. 搜索算法
  - 在ToT框架内， 根据树结构插入和使用不同的搜索算法。
    - a. 广度优先搜索：每步维护一组最有希望的状态集合, 适用于创意写作等树深度受到限制的任务
    - b. 深度优先搜索： 首先探索最有希望的状态，直到达到最终输出结果， 或者状态评估器认为无法解决当下问题，回溯父状态继续探索。


思维树具有以下几个优势：
- 泛化性：IO, CoT, CoT-SC 和自我完善都可以看做是ToT的特殊情况
- 模块化： 基本LM以及思考分解，生成，评估和搜索过程都可以独立变化
- 适应性： 可以适应不同问题属性， LM能力，和资源约束
- 方便性： 无需额外训练， 只需要一个预训练好的LM（大语言模型）就够了。


# 大模型开发

## 字符编码的发展

存储阶段：完成信息存储
  - ascii：最开始是ascii编码只能表示英文字符
  - unicode: 后面发展成unicode编码，能表示全世界所有字符
统计阶段：
  - one-hot编码（词汇表）：在机器学习和深度学习应用中， 文本数据通常要转换为数值类型， one-hot 编码是一种常用的转换方式，在one-hot编码中， 每个汉字都被表示为一个只有一个元素为1，其余元素为0的向量。向量长度等于汉字的总数量，1的位置表示该汉字的索引。
  one-hot的优点在于它简单直观， 但是当汉子数量非常大时， one-hot编码会占用大量内存， 而且只能表示汉字本身，不能表示出字与字之间语义的联系。
学习阶段：
  - 基于深度学习的语言模型： 这种技术将每个字或者词映射到一个高维向量（称为词嵌入），这个向量可以捕获到字或者词的语义信息，并且可以做运算。


## 表示学习： 让计算机更好的理解世界

表示学习（Representation learning）是指通过学习算法*自动地*从原始数据中学到一种表示形式或者特征表示，该表示形式能够*更好的表达数据的重要特征和结构*。表示学习的目标是将输入数据转换为具有良好表示能力的特征空间，使得该空间的数据具有更好的可分性， 可解释性或者推理能力。

可分性： 学到的表示，在*不同类别，不同概念之间的样本应该有明显的边界或者区别*；

可解释性： 学到的特征表示， 具有对应原始数据中的可理解概念或者语义的含义。例如，在自然语言处理中， 词嵌入模型学习到的词向量应该能够捕捉到*词语之间的语义关系*， 使得相近的词在向量空间中更接近。

推理能力： 学到的特征表示，在推理任务重更具能力， 这意味着在特征空间中， 我们可以执行类似于*推理， 类比或者关联*的操作。例如， 通过在词嵌入空间中执行向量运算， 如“国王”-"男人"+“女人”，我们可以得到与“皇后”非常接近的结果。

## 嵌入(Embedding)的价值

Embedding本身也是一种表示学习，包括词嵌入，图像嵌入，图嵌入。词嵌入可以通过World2Vec来学， 图像嵌入可以通过卷积神经网络来学，图（图结构）可以通过DeepWalk来学。 

1. 降维： 在许多实际问题中原始数据的维度往往非常高。通过Embedding, 我们可以将高维数据， 映射到一个低维空间，大大减少了模型的复杂度。

2. 捕捉语义信息： 能够捕捉数据的语义信息，可以保留并利用原始数据的一些重要信息。

3. 适应性： Embedding通过数据驱动的方式学习，这意味着它能够自适应数据的特性， 而无需人工设计特征

4. 泛化能力： Embedding能够捕捉到数据的一些内在规律， 对于一些未见过的数据， Embedding仍然能够给出合理的表示

5. 可解释性： 尽管Embedding 是高维的， 但我们仍然可以通过一些可视化工具（如t-SNE）来观察和理解Embedding的结构。
   这对于理解模型的行为， 以及发现数据的一些潜在规律是非常有用的。

##  和大语言模型高度相关的：word Embedding


word Embedding为自然语言处理任务提供了更好的单词表示方法， 他的应用主要有：

- 语义表示和语义相似度： 可以捕捉单词之间的语义关系， 使得相似含义的单词在向量空间彼此靠近。
- 词语关系和类比推理： 通过在向量空间进行运算， 可以发现词语之间的关系，比如近义词，反义词， 上下位等关系。
- 上下文理解： 帮助理解上下文的单词信息。
- 文本分类和情感分析：
- 机器翻译和生成模型： 通过将源语言和目标语言的单词都映射为嵌入向量， 可以提高翻译的准确性和生成模型的质量。


![embeding和大语言模型的关系](img/embeding和大语言模型的关系.png)

word Embedding 和 大语言模型的关系：

Word Embedding: 词嵌入通常被用来生成词的向量表示， 这个过程通常是*静态*的， 即一旦训练完成每个词的向量表示就确定了。词嵌入的主要目标是捕获单词和短语的语义和语法信息，并将这些信息以向量的形式表示出来。词嵌入并不能理解上下文信息。

Language Model: 语言模型则是预测词序列的概率模型， 这个过程通常是动态的， 会根据输入的上下文进行变化， 语言模型的主要目标是理解和生成文本。这包括对上下文的理解，词的预测， 句子的生成等等。语言模型会用到词嵌入。

可以理解为词嵌入式语言模型的一部分或者输入，现在有一些更先进的模型比如bert,gpt, 他们生成的上下文相关的词嵌入， 即词嵌入会根据上下文变化，这一定程度上弥补里传统词嵌入模型的不足。


## Embedding 实战


## todo

底层原理： 注意力机制， transformer

api：ebeding,  model, completions（生成类）， chat completions(对话类， 包含几个角色： 系统，用户)

ai+: functioncalling 的机制


chatgptplugin : 低优先级

hugging face ==> ai的github


# langchain

一个快速崛起的开源项目， 通过组合模块和能力抽象来扩展LLM的助手， 目前在aigc 应用开发生态里，大语言模型开发，最核心的框架，没有一个同等量级的框架跟它pk

LangChain是一个用于*开发由语言模型驱动的应用程序*的框架

## langchain核心模块

LLM, Memory, prompt, agent

### 标准化大模型的抽象： Model I/O

Model input output

Model I/O 是 LangChain 为开发者提供的一套面向 LLM 的标准化模型接口，包括模型输入（Prompts）、模型输出（Output Parsers）和模型本身（Models）。

Prompts：模板化、动态选择和管理模型输入
  - 模版字符串： 里面可以用{}做占位变量
  - 各种模版(from)： 提示（字符串）模板（PromptTemplate），聊天模版（ChatPromptTemplate），示例模版（FewShotPromptTemplate）
    - PromptTemplate.fromTemplate
    - ChatPromptTemplate.fromMessages
  - 格式化（format）： 通过模版字符串和模版，格式化成最终给大模型的提示
    - prompt.fomat(模版变量值/对象)
Models：以*通用接口*调用语言模型
Output Parser：从模型输出中提取*结构化信息*，因为大模型输入的是自然语言


#### 模型抽象 Model

通常用两类模型：语言模型(LLMs) 和  聊天模型(Chat Models)
- 那么相对应的模版也有两类基本模版： PromptTemplate 和 ChatPromptTemplate， 加一类实例模版FewShotPromptTemplate


语言模型(LLMs): LangChain 的核心组件。LangChain并不提供自己的LLMs，而是为与许多不同的LLMs（OpenAI、Cohere、Hugging Face等）进行交互*提供了一个标准接口*。

聊天模型(Chat Models): 语言模型的一种变体。虽然聊天模型在内部使用了语言模型，但它们提供的接口略有不同。与其暴露一个“输入文本，输出文本”的API不同，它们提供了一个以“聊天消息”作为输入和输出的接口。
（注：对比 OpenAI Completion API和 Chat Completion API）


#### chains


chains: 为对组件的一系列调用，其中可以包括其他链, 比如 复杂的应用程序需要将 LLM 相互链接或与其他组件链接。

chain的触发： run, call, invoke， 三者都能触发链

run： run就是简单调用传字符串值（模版字符串以只有一个变量就可以用这个）
call： 第一个参数变量对象，第二个参数回调函数数组或者请求配置（接收流式数据可能需要）
invoke： 第一个参数变量对象， 第二个参数链执行配置


基础链： LLMChain
串行链： SimpleSequentialChain， SequentialChain
路由链： RouterChain (给不同的提示模版，大语言模型根据你对模版的描述，然后根据你的问题自动决定用哪个模版)


#### memory

BufferMemory： 简单粗暴的全部记下来，有可能就超过最大token数
BufferWindowMemory： 窗口记忆，记忆有限轮次的对话
ConversationSummaryMemory： 将对话总结后然后记忆，不限轮次，限制token，决定何时清除超出部分， 
ConversationSummaryBufferMemory：  内存中保留一部分聊天内容的摘要,和一部分的多轮聊天内容，但是要在内存中保留多少轮聊天内容,这取决于参数maxTokenLimit，如果将maxTokenLimit设置为较小的值时，那么大部分之前的聊天内容都被转换成了摘要，反之同理；
